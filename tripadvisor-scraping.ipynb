{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fad42cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import random\n",
    "import time, os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e491b9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efd432a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5f00a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromedriver = \"/Applications/chromedriver\" # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d989e712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_page_name(soup):\n",
    "    try: \n",
    "        name = soup.find('h1', id='HEADING').text\n",
    "    except:\n",
    "        name = 'empty'\n",
    "    return name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9522815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rating(soup):\n",
    "    try:\n",
    "        rating = soup.find('span', class_=\"bvcwU P\").text\n",
    "    except: \n",
    "        rating = 'empty'\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a867327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_address(soup):\n",
    "    try:\n",
    "        address = soup.find('span', class_=\"ceIOZ yYjkv\").text\n",
    "    except:\n",
    "        address = 'empty'\n",
    "    return address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffcdd29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_amenities(soup):\n",
    "    try: \n",
    "        amenity_tags = soup.find_all(class_=\"exmBD K\")\n",
    "    except:\n",
    "        property_amenities = 'empty'\n",
    "        room_features = 'empty'\n",
    "        room_types = 'empty'\n",
    "    else:\n",
    "        try:\n",
    "            property_amenities =  [item.text for item in amenity_tags[0].find_all(attrs = {'class':\"bUmsU f ME H3 _c\", 'data-test-target': 'amenity_text'})]\n",
    "        except:\n",
    "            property_amenities = 'empty'\n",
    "        try: \n",
    "            room_features = [item.text for item in amenity_tags[1].find_all(attrs = {'class':\"bUmsU f ME H3 _c\", 'data-test-target': 'amenity_text'})]\n",
    "        except:\n",
    "            room_features = 'empty'\n",
    "        try:\n",
    "            room_types = [item.text for item in amenity_tags[2].find_all(attrs = {'class':\"bUmsU f ME H3 _c\", 'data-test-target': 'amenity_text'})]\n",
    "        except:\n",
    "            room_types = 'empty'\n",
    "    return property_amenities, room_features, room_types\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc55c40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#UPDATED \n",
    "def find_languages(soup):\n",
    "    try:\n",
    "        languages = soup.find(text='Languages Spoken').next.text\n",
    "    except:\n",
    "        languages = 'empty'\n",
    "    return languages\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d57881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hotel_styles(soup):\n",
    "    hotel_styles = []\n",
    "    try:\n",
    "        for item in soup.find_all(class_=\"dyJVb Ci S2 H2 b Wf\"):\n",
    "            if item.text == 'HOTEL STYLE':\n",
    "                next_siblings = item.find_next_siblings(class_=\"drcGn _R MC S4 _a H\")\n",
    "                for sibling in next_siblings:\n",
    "                    hotel_styles.append(sibling.text)\n",
    "    except:\n",
    "        hotel_styles = \"empty\"\n",
    "    return hotel_styles \n",
    "                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcbdec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_star_class(soup):\n",
    "    try:\n",
    "        stars = soup.find('svg',class_= 'TkRkB d H0')['title']\n",
    "    except:\n",
    "        stars = 'empty'\n",
    "    return stars\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b08e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_walkability(soup):\n",
    "    try:\n",
    "        score = soup.find('div', class_=\"eaCqs u v ui_column is-4\").text\n",
    "    except:\n",
    "        score = 'empty'\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5993c90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_proximity(soup):\n",
    "    try:\n",
    "        distances = [item.text for item in soup.find_all(class_=\"ehKIl\")]\n",
    "    except:\n",
    "        restaurants_distance = 'empty'\n",
    "        attractions_distance = 'empty'\n",
    "    else:\n",
    "        try:\n",
    "            restaurants_distance = soup.find('span', class_ = \"bpwqy VyMdE\").text + ' ' + soup.find('span', class_ = \"hqMZC H3 b bBSTv\").text + ' ' + distances[1]\n",
    "        except:\n",
    "            restaurants_distance = 'empty'\n",
    "        try: \n",
    "            attractions_distance = soup.find('span', class_ = \"bpwqy eKwbS\").text + ' ' + soup.find('span', class_ = \"hqMZC H3 b fBLNb\").text + ' ' + distances[2]\n",
    "        except:\n",
    "            attractions_distance = 'empty'\n",
    "    return restaurants_distance, attractions_distance \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79952ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_reviews(soup):\n",
    "    try: \n",
    "        reviews = soup.find(class_='HFUqL').text\n",
    "    except:\n",
    "        reviews = 'empty'\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ecc9144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_precautions(soup):\n",
    "    try:\n",
    "        precautions = [item.text for item in soup.find_all('span', class_=\"ctpJG\")]\n",
    "    except:\n",
    "        precautions = 'empty'\n",
    "    return precautions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33a68854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_page_elements(hotel_dict):\n",
    "    try:\n",
    "        driver.find_element_by_xpath('//*[@id=\"COVID19\"]/div/div[2]/div[1]/div[1]/div[2]').click()\n",
    "    except:\n",
    "        pass\n",
    "    finally:\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    \n",
    "        hotel_dict[\"Page Name\"] = find_page_name(soup) #double checking\n",
    "        hotel_dict['Tripadvisor Rating'] = find_rating(soup)\n",
    "        hotel_dict['Address'] = find_address(soup)\n",
    "    \n",
    "        amenities = find_amenities(soup)\n",
    "        hotel_dict['Property Amenities'] = amenities[0]\n",
    "        hotel_dict['Room Features'] = amenities[1]\n",
    "        hotel_dict['Room Types'] = amenities[2]\n",
    "    \n",
    "        \n",
    "        hotel_dict['Hotel Style'] = find_hotel_styles(soup)\n",
    "        hotel_dict['Languages'] = find_languages(soup)\n",
    "    \n",
    "        hotel_dict['Hotel Star Class'] = find_star_class(soup)\n",
    "        hotel_dict['Car/Walkability'] = find_walkability(soup)\n",
    "    \n",
    "        nearby = find_proximity(soup)\n",
    "        hotel_dict['Restaurants Proximity'] = nearby[0]\n",
    "        hotel_dict['Attractions Proximity'] = nearby[1]\n",
    "    \n",
    "        hotel_dict['Number of Reviews'] = find_reviews(soup)\n",
    "        hotel_dict['Covid Precautions'] = find_precautions(soup)\n",
    "    return hotel_dict\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1236834",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.tripadvisor.com/Hotels-g529023-Shoalhaven_New_South_Wales-Hotels.html\"\n",
    "\n",
    "#driver = webdriver.Chrome(chromedriver,options=options)\n",
    "driver = webdriver.Chrome(chromedriver)\n",
    "driver.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "9846b0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22262751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default number of scraped pages\n",
    "num_page = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d1bdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file to save the review\n",
    "#csvFile = open(path_to_file, 'a', encoding=\"utf-8\")\n",
    "#csvWriter = csv.writer(csvFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9dd8f59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_list(urls, hotels):\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//*[@id='HEADING']/span\").click()\n",
    "    except:\n",
    "        pass\n",
    "    finally:\n",
    "        time.sleep(3)\n",
    "        for num, url in enumerate(urls):\n",
    "            hotel_dict = {}\n",
    "            hotel_dict['Name'] = driver.find_elements_by_class_name(\"listing_title\")[num].text\n",
    "            try:\n",
    "                hotel_dict['Featured Price'] = driver.find_elements_by_class_name(\"price-wrap\")[num].text\n",
    "            except:\n",
    "                hotel_dict['Featured Price'] = 'empty'\n",
    "            try:\n",
    "                hotel_dict['Category'] = driver.find_elements_by_class_name(\"mb10\")[num].text\n",
    "            except:\n",
    "                hotel_dict['Category'] = 'empty'\n",
    "            finally:\n",
    "                main_page = driver.current_window_handle\n",
    "                WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \".//div[@class='listing_title']/a\")))\n",
    "                urls[num].click()  \n",
    "                driver.switch_to.window(driver.window_handles[1])\n",
    "                time.sleep(5)\n",
    "                full_dict = extract_page_elements(hotel_dict)\n",
    "                hotels.append(full_dict)\n",
    "                driver.close()\n",
    "                driver.switch_to.window(main_page)\n",
    "                time.sleep(3 + 2*random.random())\n",
    "        return hotels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bba5c0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "destinations = {\n",
    "    #'Phillip Island': 'https://www.tripadvisor.com/Hotels-g504338-Phillip_Island_Victoria-Hotels.html',\n",
    "    #'Gold Coast': 'https://www.tripadvisor.com/Hotels-g255337-Gold_Coast_Queensland-Hotels.html',\n",
    "    #'Port Stephens': 'https://www.tripadvisor.com/Hotels-g529017-Port_Stephens_Greater_Newcastle_New_South_Wales-Hotels.html',\n",
    "    #'Cowes': 'https://www.tripadvisor.com/Hotels-g261657-Cowes_Phillip_Island_Victoria-Hotels.html',\n",
    "    #'Melbourne': 'https://www.tripadvisor.com/Hotels-g255100-oa210-Melbourne_Victoria-Hotels.html', #broke\n",
    "    #'Noosa': 'https://www.tripadvisor.com/Hotels-g261678-Noosa_Sunshine_Coast_Queensland-Hotels.html',\n",
    "    #'Port Douglas': 'https://www.tripadvisor.com/Hotels-g255070-Port_Douglas_Queensland-Hotels.html',\n",
    "    #'Sydney': 'https://www.tripadvisor.com/Hotels-g255060-Sydney_New_South_Wales-Hotels.html',\n",
    "    #'Jervis Bay': 'https://www.tripadvisor.com/Hotels-g528972-Jervis_Bay_Shoalhaven_New_South_Wales-Hotels.html',\n",
    "    #'Kangaroo Island': 'https://www.tripadvisor.com/Hotels-g255095-Kangaroo_Island_South_Australia-Hotels.html',\n",
    "    #'Airlie Beach': 'https://www.tripadvisor.com/Hotels-g261596-Airlie_Beach_Queensland-Hotels.html', \n",
    "    #'Hervey Bay': 'https://www.tripadvisor.com/Hotels-g255404-Hervey_Bay_Fraser_Coast_Queensland-Hotels.html',\n",
    "    #'Busselton': 'https://www.tripadvisor.com/Hotels-g261672-Busselton_Margaret_River_Region_Western_Australia-Hotels.html',\n",
    "    #'Toowoomba': 'https://www.tripadvisor.com/Hotels-g255340-Toowoomba_Queensland-Hotels.html'\n",
    "    }\n",
    "\n",
    "#doesn't include shoalhaven which was already extracted\n",
    "#jervis bay contains some shoalhaven locations--remove duplicates during data cleaning oricess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08c9b22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_csv(list_dict, destination):\n",
    "    keys = list_dict[0].keys()\n",
    "    with open(f'{destination}.csv', 'a', newline='') as file:\n",
    "        dict_writer = csv.DictWriter(file, keys)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(list_dict)\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef7dd8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hotel_scraper(destination):\n",
    "    while True:\n",
    "        time.sleep(5)\n",
    "        #WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.LINK_TEXT('Next'))))\n",
    "        next_button = driver.find_elements_by_link_text('Next')\n",
    "        if len(next_button) <1:\n",
    "            print(\"no more pages left\")\n",
    "            break\n",
    "        else:\n",
    "            hotels = []\n",
    "            #driver.switch_to.window(driver.current_window_handle)\n",
    "            hotel_urls = driver.find_elements_by_xpath(\".//div[@class='listing_title']/a\")\n",
    "            #print(hotel_urls)\n",
    "            list_dict = making_list(hotel_urls, hotels)\n",
    "            add_to_csv(list_dict, destination)\n",
    "            driver.find_element_by_link_text('Next').click()\n",
    "            print('clicked')\n",
    "            time.sleep(10 + 2*random.random()) \n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0b04603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicked\n",
      "clicked\n",
      "clicked\n",
      "no more pages left\n",
      "Busselton 1238.708848953247\n",
      "clicked\n",
      "clicked\n",
      "no more pages left\n",
      "Toowoomba 627.0990788936615\n"
     ]
    }
   ],
   "source": [
    " for destination in destinations:\n",
    "        driver = webdriver.Chrome(chromedriver)\n",
    "        driver.get(destinations[destination])\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        time.sleep(7)\n",
    "        t0 = time.time()\n",
    "        hotel_scraper(destination)\n",
    "        print(destination, time.time() - t0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
